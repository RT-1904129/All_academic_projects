{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q.1 Using the make_blobs function in sklearn generate a dataset of 100 points with two classes. Implement Logistic regression with cross entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries and important modules\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import make_blobs\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the make_blobs function in sklearn to generate a dataset of 100 points with two classes\n",
    "X, y = make_blobs(n_samples = 100, centers = 2, cluster_std = 1, n_features = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Logistic Regression Class\n",
    "class LogisticRegression() :\n",
    "    def __init__(self, learning_rate, iterations):\n",
    "        self.learning_rate = learning_rate        \n",
    "        self.iterations = iterations\n",
    "    # Cross Entropy Loss \n",
    "    def loss(self, h, y):\n",
    "        return (-y.T.dot(np.log(h)) - (1 - y).T.dot(np.log(1 - h)))/len(y)\n",
    "    # Model Training  \n",
    "    def fit(self, X, Y):        \n",
    "        # No. of Training Examples, No. of Features given by X.shape      \n",
    "        self.m, self.n = X.shape        \n",
    "        # Weight Initialization        \n",
    "        self.W = np.zeros(self.n)        \n",
    "        self.b = 0        \n",
    "        self.X = X        \n",
    "        self.Y = Y\n",
    "        # Gradient Descent Learning\n",
    "        cost_list=[]\n",
    "        # To store the costs in a list after each weight updation\n",
    "        for i in range(self.iterations):\n",
    "            cost_list.append(self.update_weights())\n",
    "        return cost_list\n",
    "      \n",
    "    # Updation of Weights during Gradient Descent \n",
    "    def update_weights(self):\n",
    "        A = 1/(1 + np.exp(-(self.X.dot(self.W) + self.b))) #Sigmoid Activation Function\n",
    "        # Gradients Calculation (Derivative of Loss Function with respect to weights)\n",
    "        p = ( A - self.Y.T )        \n",
    "        p = np.reshape(p, self.m)     \n",
    "        dW = np.dot(self.X.T, p)/self.m         \n",
    "        db = np.sum(p)/self.m \n",
    "        # Updation of Weights\n",
    "        self.W = self.W - self.learning_rate * dW    \n",
    "        self.b = self.b - self.learning_rate * db\n",
    "        return self.loss(A,self.Y)\n",
    "    \n",
    "    # Prediction on Dataset X; if result from Sigmoid Activation Function is greater than 0.5, result is 1 else 0\n",
    "    def predict(self, X):\n",
    "        Z = 1/( 1 + np.exp(-(X.dot(self.W) + self.b)))        \n",
    "        Y = np.where( Z > 0.5, 1, 0 )        \n",
    "        return Y \n",
    "    # Defining the F1 Score (2PR/P+R)\n",
    "    def F1_score(self,y,y_pred):\n",
    "        tp,tn,fp,fn = 0,0,0,0 # True Positive, True Negative, False Positive, False Negative\n",
    "        for i in range(len(y)):\n",
    "            if y[i] == 1 and y_pred[i] == 1:\n",
    "                tp += 1\n",
    "            elif y[i] == 1 and y_pred[i] == 0:\n",
    "                fn += 1\n",
    "            elif y[i] == 0 and y_pred[i] == 1:\n",
    "                fp += 1\n",
    "            elif y[i] == 0 and y_pred[i] == 0:\n",
    "                tn += 1\n",
    "        precision = tp/(tp+fp)\n",
    "        recall = tp/(tp+fn)\n",
    "        f1_score = 2*precision*recall/(precision+recall)\n",
    "        return f1_score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the Dataset into Training and Test Set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "# Using the above defined Logistic Regression class for Model Training    \n",
    "model_LR = LogisticRegression(learning_rate = 0.01, iterations = 100)\n",
    "Cost = model_LR.fit(X_train, y_train)\n",
    "y_pred = model_LR.predict(X_test)\n",
    "f1score = model_LR.F1_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Logistic Regression Model on Test Set (%) : 100.0\n",
      "F1 Score of the Logistic Regression Model on Test Set: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Accuracy Calculation\n",
    "count = 0    \n",
    "cc=0\n",
    "for count in range(np.size(y_pred)):\n",
    "    if y_test[count] == y_pred[count]:\n",
    "        cc=cc+1\n",
    "    count=count+1\n",
    "accuracy = (cc/count) * 100\n",
    "print(\"Accuracy of the Logistic Regression Model on Test Set (%) :\", accuracy)\n",
    "print(\"F1 Score of the Logistic Regression Model on Test Set:\", f1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot of the Cost Function for every iteration\n",
    "xpoints = np.arange(0,100,1)\n",
    "plt.plot(xpoints,Cost)\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The make_blobs function in sklearn has been used to generate a dataset of 100 points with two classes.\n",
    "2. The Loss Function used in the Logistic Regression Model is the Cross Entropy Loss.\n",
    "3. Cross Entropy Loss: L = (-ylog(h) - (1 - y)log(1 - h))/m where m is the number of training examples.\n",
    "4. The Gradients are computed through calculation of derivative of loss Function with respect to weights and the Weights, Bias are suitably updated using an input learning rate.\n",
    "5. During prediction, the sigmoid activation function is applied to W*X+B. \n",
    "6. If result from sigmoid activation function is greater than 0.5, a value of 1 is outputted else 0 is outputted.\n",
    "7. The Dataset is split into Training set(75%) and Test set(25%). The Logistic Regression Model is fit on the Training Dataset with an input learning rate=0.01 and run for 100 iterations.\n",
    "8. The Accuracy and F1-score on the Test set from the Logistic Regression Model  is outputted.\n",
    "7. A Plot of the Cost function vs Iteration is shown above. We can observe that the Cost gradually decreases as number of iterations increases. \n",
    "8. We observe that as the estimated weights and bias approach the true values,the loss reduces with each iteration increase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. https://www.analyticsvidhya.com/blog/2022/02/implementing-logistic-regression-from-scratch-using-python/\n",
    "2. https://www.geeksforgeeks.org/implementation-of-logistic-regression-from-scratch-using-python/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
