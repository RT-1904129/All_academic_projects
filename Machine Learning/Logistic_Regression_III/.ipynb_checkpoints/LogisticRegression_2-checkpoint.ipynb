{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f_KVeXRQouHU"
   },
   "source": [
    "## III Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Using the make blobs function in sklearn generate a dataset of 100 points with two classes. Implement Logistic regression with least mean square loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YNljtaI6ouHZ"
   },
   "outputs": [],
   "source": [
    "# Importing libraries and important modules\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import make_blobs\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "e-J-wLSfum8S"
   },
   "outputs": [],
   "source": [
    "# Using the make_blobs function in sklearn to generate a dataset of 100 points with two classes\n",
    "X, y = make_blobs(n_samples = 100, centers = 2, cluster_std = 1, n_features = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Zka54z8GTw8t"
   },
   "outputs": [],
   "source": [
    "# Defining the Logistic Regression Class\n",
    "class LogisticRegression() :\n",
    "    def __init__(self, learning_rate, iterations):\n",
    "        self.learning_rate = learning_rate        \n",
    "        self.iterations = iterations\n",
    "\n",
    "    # Squared Error Loss (LMS)\n",
    "    def loss(self, h, y):\n",
    "        loss = (1/len(y))*np.sum(np.square(h - y))\n",
    "        return loss\n",
    "\n",
    "    # Model Training  \n",
    "    def fit(self, X, Y):        \n",
    "        # No. of Training Examples, No. of Features given by X.shape      \n",
    "        self.m, self.n = X.shape        \n",
    "        # Weight Initialization        \n",
    "        self.W = np.zeros(self.n)        \n",
    "        self.b = 0        \n",
    "        self.X = X        \n",
    "        self.Y = Y\n",
    "        # Gradient Descent Learning\n",
    "        cost_list=[]\n",
    "        for i in range(self.iterations):\n",
    "            cost_list.append(self.new_weights())\n",
    "        return cost_list\n",
    "      \n",
    "    # Updation of Weights during Gradient Descent \n",
    "    def new_weights(self):\n",
    "        A = 1/(1 + np.exp(-(self.X.dot(self.W) + self.b))) #Sigmoid Activation Function\n",
    "        # Gradients Calculation (Derivative of Loss Function with respect to weights)\n",
    "        dW = - (2 *( self.X.T ).dot( self.Y - A) )/self.m\n",
    "        db = - 2 * np.sum(self.Y - A)/self.m \n",
    "        # Updation of Weights\n",
    "        self.W = self.W - self.learning_rate * dW    \n",
    "        self.b = self.b - self.learning_rate * db\n",
    "        return self.loss(A,self.Y)\n",
    "    \n",
    "    # Prediction on Dataset X; if result from Sigmoid Activation Function is greater than 0.5, result is 1 else 0\n",
    "    def predict(self, X):\n",
    "        Z = 1/( 1 + np.exp(-(X.dot(self.W) + self.b)))        \n",
    "        Y = np.where( Z > 0.5, 1, 0 )        \n",
    "        return Y \n",
    "    # Defining the F1 Score (2PR/P+R)\n",
    "    def F1_score(self,y,y_pred):\n",
    "        tp,tn,fp,fn = 0,0,0,0 # True Positive, True Negative, False Positive, False Negative\n",
    "        for i in range(len(y)):\n",
    "            if y[i] == 1 and y_pred[i] == 1:\n",
    "                tp += 1\n",
    "            elif y[i] == 1 and y_pred[i] == 0:\n",
    "                fn += 1\n",
    "            elif y[i] == 0 and y_pred[i] == 1:\n",
    "                fp += 1\n",
    "            elif y[i] == 0 and y_pred[i] == 0:\n",
    "                tn += 1\n",
    "        precision = tp/(tp+fp)\n",
    "        recall = tp/(tp+fn)\n",
    "        f1_score = 2*precision*recall/(precision+recall)\n",
    "        return f1_score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "o1EJ-8DHT0v5"
   },
   "outputs": [],
   "source": [
    "# Splitting the Dataset into Training and Test Set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "# Using the above defined Logistic Regression class for Model Training    \n",
    "model_learning_rate = LogisticRegression(learning_rate = 0.01, iterations = 100)\n",
    "Cost = model_learning_rate.fit(X_train, y_train)\n",
    "y_pred = model_learning_rate.predict(X_test)\n",
    "f1score = model_learning_rate.F1_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ze8aHQ8AT5DB",
    "outputId": "1e7daa28-9931-440b-ab7d-19779aa5308a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Logistic Regression Model on Test Set (%) : 100.0\n",
      "F1 Score of the Logistic Regression Model on Test Set: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Accuracy Calculation\n",
    "count = 0    \n",
    "cc=0\n",
    "for count in range(np.size(y_pred)):\n",
    "    if y_test[count] == y_pred[count]:\n",
    "        cc=cc+1\n",
    "    count=count+1\n",
    "accuracy = (cc/count) * 100\n",
    "print(\"Accuracy of the Logistic Regression Model on Test Set (%) :\", accuracy)\n",
    "print(\"F1 Score of the Logistic Regression Model on Test Set:\", f1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "sh9WUrq8T_En",
    "outputId": "347f1508-a0d5-4e6a-8135-2102765edb43"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot of the Cost Function with every iteration\n",
    "xpoints = np.arange(0,100,1)\n",
    "plt.plot(xpoints,Cost)\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Qh4GQm4HGlI"
   },
   "source": [
    "### Observations :\n",
    "1. The success of the Logistic Regression model depends on the `sample sizes and the loss function`.\n",
    "2. If result from sigmoid activation function is `greater than 0.5, a value of 1 is outputted else 0 is outputted.`\n",
    "3. The Gradients are computed through calculation of derivative of loss function with respect to weights and the Weights, Bias are suitably updated using an input learning rate.\n",
    "4. Here, We are using the `least mean squared error` as the loss on the output of `sigmoid activation`; a `non-linear transformation`, which causes a problem of `non-convexity` with local minimums making it difficult to find the global minimum. As a result `least mean squared error` as a loss function is not preferred in case of logistic regression.\n",
    "5. A Plot of the Cost function vs Iteration is shown above. We can observe that the Cost gradually decreases as number of iterations increases.\n",
    "6. We observe that as the estimated weights and bias approach the true values,the loss reduces with each iteration increase.\n",
    "7. We can also observe that this decrease is less smoother compared to the logistic regression model built with cross-entropy loss implying that `least mean squared error` as a loss function is less desirable for a logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "1. https://www.geeksforgeeks.org/implementation-of-logistic-regression-from-scratch-using-python/"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LogisticRegression_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
